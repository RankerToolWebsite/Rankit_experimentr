{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "import ast\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load data (pre-processed in clean.ipynb) and define useful constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "# res = pd.read_csv(\"results/results_cleaned.csv\")\n",
    "res = pd.read_csv(\"results/results_cleaned_no_outliers.csv\").sort_values('timestamp').reset_index()\n",
    "\n",
    "# required fields\n",
    "ids = ['timestamp','postId','workerId','mode']\n",
    "\n",
    "# interactions\n",
    "inter = ['timestamp','postId','workerId','mode','interaction','UrlChanges', 'highUrlChanges', \n",
    "       'lowUrlChanges', 'medUrlChanges', 'model', 'pop_time']\n",
    "\n",
    "modes = [\"List\", \"Category\", \"Pairwise\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First count adds/removes without considering swaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inter_l = ['timestamp','workerId','mode','interaction','UrlChanges'] \n",
    "inter_c = ['timestamp','workerId','mode','interaction','highUrlChanges', 'lowUrlChanges', 'medUrlChanges']\n",
    "inter_p = ['timestamp','workerId','mode','interaction','highUrlChanges', 'lowUrlChanges']\n",
    "\n",
    "ints = {}\n",
    "ints['l'] = res[inter_l][res['mode']=='List'].drop_duplicates(subset=['workerId','interaction','UrlChanges'])\n",
    "ints['c'] = res[inter_c][res['mode']=='Category'].drop_duplicates(subset=['workerId','interaction','highUrlChanges', \n",
    "                                                                'lowUrlChanges', 'medUrlChanges'])\n",
    "ints['p'] = res[inter_p][res['mode']=='Pairwise'].drop_duplicates(subset=['workerId','interaction','highUrlChanges', \n",
    "                                                                'lowUrlChanges'])\n",
    "for i in ints:\n",
    "    ints[i] = ints[i].groupby(['workerId']).apply(pd.DataFrame.sort_values, 'timestamp')\n",
    "    ints[i] = ints[i].reset_index(drop=True)\n",
    "    ints[i].dropna(subset =['interaction'])\n",
    "    \n",
    "adds = {}\n",
    "adds['List'] = ints['l'][ints['l']['interaction'] == 'ADD'].groupby('workerId').count()['interaction']\n",
    "adds['Category'] = ints['c'][ints['c']['interaction'].isin(['LOW ADD', 'HIGH ADD', 'MED ADD'])].groupby('workerId').count()['interaction']\n",
    "adds['Pairwise'] = ints['p'][ints['p']['interaction'].isin(['LEFT ADD', 'RIGHT ADD'])].groupby('workerId').count()['interaction']\n",
    "\n",
    "removes = {}\n",
    "removes['List'] = ints['l'][ints['l']['interaction'] == 'REMOVE'].groupby('workerId').count()['interaction']\n",
    "removes['Category'] = ints['c'][ints['c']['interaction'].isin(['LOW REMOVE', 'HIGH REMOVE', 'MED REMOVE'])].groupby('workerId').count()['interaction']\n",
    "removes['Pairwise'] = ints['p'][ints['p']['interaction'].isin(['LEFT REMOVE', 'RIGHT REMOVE'])].groupby('workerId').count()['interaction']\n",
    "\n",
    "ranks = {}\n",
    "ranks['List'] = ints['l'][ints['l']['interaction'] == 'RANK'].groupby('workerId').count()['interaction']\n",
    "ranks['Category'] = ints['c'][ints['c']['interaction'] == 'RANK'].groupby('workerId').count()['interaction']\n",
    "ranks['Pairwise'] = ints['p'][ints['p']['interaction'] == 'RANK'].groupby('workerId').count()['interaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "adds1 = adds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write adds to file \n",
    "df0=pd.DataFrame()\n",
    "df0['measure'] = adds['List'].values\n",
    "df0['condition'] = 'List'\n",
    "df1=pd.DataFrame()\n",
    "df1['measure'] = adds['Category'].values\n",
    "df1['condition'] = 'Category'\n",
    "df2=pd.DataFrame()\n",
    "df2['measure'] = adds['Pairwise'].values\n",
    "df2['condition'] = 'Pairwise'\n",
    "df = pd.concat([df0,df1,df2])\n",
    "df[['condition','measure']]\n",
    "df.to_csv(\"results/adds.csv\", index=False)\n",
    "\n",
    "#write removes to file\n",
    "df0=pd.DataFrame()\n",
    "df0['measure'] = removes['List'].values\n",
    "df0['condition'] = 'List'\n",
    "df1=pd.DataFrame()\n",
    "df1['measure'] = removes['Category'].values\n",
    "df1['condition'] = 'Category'\n",
    "df2=pd.DataFrame()\n",
    "df2['measure'] = removes['Pairwise'].values\n",
    "df2['condition'] = 'Pairwise'\n",
    "df = pd.concat([df0,df1,df2])\n",
    "df[['condition','measure']]\n",
    "df.to_csv(\"results/removes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write ranks to file\n",
    "df0=pd.DataFrame()\n",
    "df0['measure'] = ranks['List'].values\n",
    "df0['condition'] = 'List'\n",
    "df1=pd.DataFrame()\n",
    "df1['measure'] = ranks['Category'].values\n",
    "df1['condition'] = 'Category'\n",
    "df2=pd.DataFrame()\n",
    "df2['measure'] = ranks['Pairwise'].values\n",
    "df2['condition'] = 'Pairwise'\n",
    "df = pd.concat([df0,df1,df2])\n",
    "df[['condition','measure']]\n",
    "df.to_csv(\"results/ranks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Next tag swaps and count again\n",
    "- swap list - remove from list and put back in list\n",
    "- swap category - remove from any bucket and place in a different bucket\n",
    "- swap pairwise - remove from any pair and put in a different pair, or move from high to low in same pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45  workers\n",
      "(3683, 7)\n",
      "(3683, 7)\n"
     ]
    }
   ],
   "source": [
    "# get all add/remove interactions for CATEGORICAL\n",
    "inter_c = ['timestamp','workerId','mode','interaction','highUrlChanges', 'lowUrlChanges', 'medUrlChanges']\n",
    "cat = res[inter_c][res['mode']=='Category'].drop_duplicates(subset=['workerId','interaction','highUrlChanges', \n",
    "                                                                'lowUrlChanges', 'medUrlChanges'])\n",
    "cat =cat[cat['interaction'].isin(['LOW ADD', 'HIGH ADD', 'MED ADD','LOW REMOVE', 'HIGH REMOVE', 'MED REMOVE'])]\n",
    "workers_c = cat['workerId'].unique()\n",
    "print(len(workers_c), \" workers\")\n",
    "\n",
    "# parse ids from url strings\n",
    "for s in ['lowUrlChanges','medUrlChanges','highUrlChanges']:\n",
    "    cat[s] = cat[s].apply(lambda x: np.array(ast.literal_eval(x)).astype(np.int))\n",
    "print(cat.shape)\n",
    "print(cat.dropna().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count swaps in CATEGORICAL mode\n",
    "for w in workers_c:\n",
    "#     print(w)\n",
    "    c = cat[cat['workerId']==w]\n",
    "    m = c[['highUrlChanges','medUrlChanges','lowUrlChanges','interaction']].transpose()\n",
    "    diffs = pd.DataFrame()\n",
    "#     print(m.columns.values)\n",
    "    for i,s in enumerate(m.columns.values):\n",
    "        if i<len(m.columns.values)-1:\n",
    "            nxt = m.columns.values[i+1]\n",
    "            row =[]\n",
    "            for j in ['lowUrlChanges','medUrlChanges','highUrlChanges']:\n",
    "                row.append(np.setxor1d(m[s][j], m[nxt][j]))\n",
    "            row.append(m[nxt].loc['interaction'])\n",
    "            diffs[s] = row\n",
    "    to_swap = []\n",
    "    to_drop = []\n",
    "    for i,s in enumerate(diffs.columns.values[:-2]):\n",
    "#       whenever an item is removed\n",
    "        if diffs[s][3] in ['LOW REMOVE', 'HIGH REMOVE', 'MED REMOVE']:\n",
    "#       check if it is added on the next interaction\n",
    "            nxt = diffs.columns.values[i+1]\n",
    "            for j in [0,1,2]:\n",
    "                if not diffs[s][j].size ==0:\n",
    "#                 get item that was removed\n",
    "                    v = diffs[s][j][0]\n",
    "#                   check if it is added to nxt in a different bucket  \n",
    "                    for k in [0,1,2]:\n",
    "                        if not j==k and not diffs[nxt][k].size==0:\n",
    "                            y = diffs[nxt][k][0]\n",
    "                            if y == v:\n",
    "#                             indexes are off by one because we diff the cols\n",
    "                                to_swap.append(diffs.columns.values[i+2])\n",
    "                                to_drop.append(diffs.columns.values[i+1]) \n",
    "#   update results\n",
    "    res.loc[to_swap,'interaction'] = 'SWAP'\n",
    "    res.drop(to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48  workers\n",
      "(1032, 5)\n",
      "(1032, 5)\n"
     ]
    }
   ],
   "source": [
    "# get all add/remove interactions for LIST\n",
    "inter_l = ['timestamp','workerId','mode','interaction','UrlChanges'] \n",
    "lst = res[inter_l][res['mode']=='List'].drop_duplicates(subset=['workerId','interaction','UrlChanges'])\n",
    "lst =lst[lst['interaction'].isin(['ADD', 'REMOVE'])]\n",
    "workers_l = lst['workerId'].unique()\n",
    "print(len(workers_l), \" workers\")\n",
    "\n",
    "# parse ids from url strings\n",
    "lst['UrlChanges'] = lst['UrlChanges'].apply(lambda x: np.array(ast.literal_eval(x)).astype(np.int))\n",
    "\n",
    "print(lst.shape)\n",
    "print(lst.dropna().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count swaps in LIST mode\n",
    "# workers_l = ['A1CY7IOJ9YH136']\n",
    "for w in workers_l:\n",
    "#     print(w)\n",
    "    c = lst[lst['workerId']==w]\n",
    "    m = c[['UrlChanges','interaction']].transpose()\n",
    "    \n",
    "    to_swap = []\n",
    "    to_drop = []\n",
    "    diffs = pd.DataFrame()\n",
    "\n",
    "    for i,s in enumerate(m.columns.values):\n",
    "        if i<len(m.columns.values)-1:\n",
    "            nxt = m.columns.values[i+1]\n",
    "            row =[]\n",
    "            #       check if lengths are the same but order changed\n",
    "            if not m[s]['UrlChanges'].size == 0 and m[s]['UrlChanges'].size == m[nxt]['UrlChanges'].size:\n",
    "#                 print(s, \"same size\")\n",
    "#                 print(m[s]['UrlChanges'])\n",
    "#                 print(m[nxt]['UrlChanges'])\n",
    "                to_swap.append(nxt)\n",
    "            row.append(np.setxor1d(m[s]['UrlChanges'], m[nxt]['UrlChanges']))\n",
    "            row.append(m[nxt].loc['interaction'])\n",
    "            diffs[s] = row\n",
    "# diffs\n",
    "    for i,s in enumerate(diffs.columns.values[:-2]):\n",
    "        nxt = diffs.columns.values[i+1]\n",
    "#       whenever an item is removed\n",
    "        if diffs[s][1] == 'REMOVE':\n",
    "#       check if it is added on the next interaction\n",
    "            if not diffs[s][0].size ==0:\n",
    "#               get item that was removed\n",
    "                v = diffs[s][0][0]\n",
    "#               check if it is added to nxt in a different bucket  \n",
    "                if not diffs[nxt][0].size==0:\n",
    "                    y = diffs[nxt][0][0]\n",
    "                    if y == v:\n",
    "#                   indexes are off by one because we diff the cols\n",
    "                        to_swap.append(diffs.columns.values[i+2])\n",
    "                        to_drop.append(diffs.columns.values[i+1]) \n",
    "#   update results\n",
    "#     print(\"swap\", to_swap)\n",
    "#     print(\"drop\", to_drop)\n",
    "    res.loc[to_swap,'interaction'] = 'SWAP'\n",
    "    res.drop(to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50  workers\n",
      "(717, 6)\n",
      "(717, 6)\n"
     ]
    }
   ],
   "source": [
    "# get all add/remove interactions for PAIRWISE\n",
    "inter_p = ['timestamp','workerId','mode','interaction','highUrlChanges', 'lowUrlChanges']\n",
    "pair = res[inter_p][res['mode']=='Pairwise'].drop_duplicates(subset=['workerId','interaction','highUrlChanges', \n",
    "                                                                'lowUrlChanges'])\n",
    "pair=pair[pair['interaction'].isin(['LEFT ADD', 'RIGHT ADD','LEFT REMOVE', 'RIGHT REMOVE'])]\n",
    "workers_p = pair['workerId'].unique()\n",
    "print(len(workers_p), \" workers\")\n",
    "\n",
    "# parse ids from url strings\n",
    "for s in ['lowUrlChanges','highUrlChanges']:\n",
    "    pair[s] = pair[s].apply(lambda x: np.array(ast.literal_eval(x)).astype(np.int))\n",
    "print(pair.shape)\n",
    "print(pair.dropna().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count swaps in PAIRWISE mode\n",
    "# workers_p = ['A1GKD3NG1NNHRP']\n",
    "for w in workers_p:\n",
    "#     print(w)\n",
    "    c = pair[pair['workerId']==w]\n",
    "    m = c[['highUrlChanges','lowUrlChanges','interaction']].transpose()\n",
    "    diffs = pd.DataFrame()\n",
    "#     print(m.columns.values)\n",
    "    for i,s in enumerate(m.columns.values):\n",
    "        if i<len(m.columns.values)-1:\n",
    "            nxt = m.columns.values[i+1]\n",
    "            row =[]\n",
    "            for j in ['lowUrlChanges','highUrlChanges']:\n",
    "                row.append(np.setxor1d(m[s][j], m[nxt][j]))\n",
    "            row.append(m[nxt].loc['interaction'])\n",
    "            diffs[s] = row\n",
    "    to_swap = []\n",
    "    to_drop = []\n",
    "    for i,s in enumerate(diffs.columns.values[:-2]):\n",
    "#       whenever an item is removed\n",
    "        if diffs[s][2] in ['LEFT REMOVE', 'RIGHT REMOVE']:\n",
    "#       check if it is added on the next interaction\n",
    "            nxt = diffs.columns.values[i+1]\n",
    "            for j in [0,1]:\n",
    "                if not diffs[s][j].size ==0:\n",
    "#                 get item that was removed\n",
    "                    v = diffs[s][j][0]\n",
    "#                   check if it is added to nxt  \n",
    "                    for k in [0,1]:\n",
    "                        if not diffs[nxt][k].size==0:\n",
    "                            y = diffs[nxt][k][0]\n",
    "                            if y == v:\n",
    "#                             indexes are off by one because we diff the cols\n",
    "                                to_swap.append(diffs.columns.values[i+2])\n",
    "                                to_drop.append(diffs.columns.values[i+1]) \n",
    "#   update results\n",
    "#     print(\"swap\", to_swap)\n",
    "#     print(\"drop\", to_drop)\n",
    "    res.loc[to_swap,'interaction'] = 'SWAP'\n",
    "    res.drop(to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inter_l = ['timestamp','workerId','mode','interaction','UrlChanges'] \n",
    "inter_c = ['timestamp','workerId','mode','interaction','highUrlChanges', 'lowUrlChanges', 'medUrlChanges']\n",
    "inter_p = ['timestamp','workerId','mode','interaction','highUrlChanges', 'lowUrlChanges']\n",
    "\n",
    "ints = {}\n",
    "ints['l'] = res[inter_l][res['mode']=='List'].drop_duplicates(subset=['workerId','interaction','UrlChanges'])\n",
    "ints['c'] = res[inter_c][res['mode']=='Category'].drop_duplicates(subset=['workerId','interaction','highUrlChanges', \n",
    "                                                                'lowUrlChanges', 'medUrlChanges'])\n",
    "ints['p'] = res[inter_p][res['mode']=='Pairwise'].drop_duplicates(subset=['workerId','interaction','highUrlChanges', \n",
    "                                                                'lowUrlChanges'])\n",
    "for i in ints:\n",
    "    ints[i] = ints[i].groupby(['workerId']).apply(pd.DataFrame.sort_values, 'timestamp')\n",
    "    ints[i] = ints[i].reset_index(drop=True)\n",
    "    ints[i].dropna(subset =['interaction'])\n",
    "    \n",
    "adds = {}\n",
    "adds['List'] = ints['l'][ints['l']['interaction'] == 'ADD'].groupby('workerId').count()['interaction']\n",
    "adds['Category'] = ints['c'][ints['c']['interaction'].isin(['LOW ADD', 'HIGH ADD', 'MED ADD'])].groupby('workerId').count()['interaction']\n",
    "adds['Pairwise'] = ints['p'][ints['p']['interaction'].isin(['LEFT ADD', 'RIGHT ADD'])].groupby('workerId').count()['interaction']\n",
    "\n",
    "removes = {}\n",
    "removes['List'] = ints['l'][ints['l']['interaction'] == 'REMOVE'].groupby('workerId').count()['interaction']\n",
    "removes['Category'] = ints['c'][ints['c']['interaction'].isin(['LOW REMOVE', 'HIGH REMOVE', 'MED REMOVE'])].groupby('workerId').count()['interaction']\n",
    "removes['Pairwise'] = ints['p'][ints['p']['interaction'].isin(['LEFT REMOVE', 'RIGHT REMOVE'])].groupby('workerId').count()['interaction']\n",
    "\n",
    "\n",
    "swaps = {}\n",
    "swaps['List'] = ints['l'][ints['l']['interaction'] == 'SWAP'].groupby('workerId').count()['interaction']\n",
    "swaps['Category'] = ints['c'][ints['c']['interaction'] == 'SWAP'].groupby('workerId').count()['interaction']\n",
    "swaps['Pairwise'] = ints['p'][ints['p']['interaction'] == 'SWAP'].groupby('workerId').count()['interaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADD</th>\n",
       "      <th>ADD_NOSWAP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11BSFO4LMHPXQ</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A126IMAJ4EEE7</th>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A15SUPIZ05ZFCD</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A17V85U8PXS4LJ</th>\n",
       "      <td>56</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A196XR61DIW5GU</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A19XQH5DG3UO0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1FLEFIVFT809G</th>\n",
       "      <td>85</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1HG89IPHXW7LO</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1JGA15NKUP0BB</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1KM8AW99FFRFZ</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1N1EF0MIRSEZZ</th>\n",
       "      <td>294</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1NBX7UHTU5CKG</th>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1PF01FF85HUY4</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1PTX4IB9R34LI</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1TARNH07A75CG</th>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1TYP11M6YZUK8</th>\n",
       "      <td>254</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1XZ9MUNKFZIJG</th>\n",
       "      <td>132</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1Z3NTRGIUZ240</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A20SL254675EOK</th>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A26U4IKXMXT0ZA</th>\n",
       "      <td>56</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A28T38MOUG43YD</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A29V2XPA9H2NAN</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2BADLL5Q78E7D</th>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2BF3A9KYSEFPO</th>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2CIFCKECOSW0S</th>\n",
       "      <td>313</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2HX72NU82J6NZ</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2NGMLBFZ3YQP5</th>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2OFWFHVQOBY56</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2T5UVJCDX3C5</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2W6XZ8D8VYZCO</th>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A35PLLN5TFI4KW</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3696JXTRKL2FI</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A39K5MR4MCSC56</th>\n",
       "      <td>325</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3DLPY6ABKCXSI</th>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3J5KTBHZI60H</th>\n",
       "      <td>233</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3JAOT764X4HYB</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3ROADR7T6811</th>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3TOHZTNKOTFQL</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3TUCOUVSP9ZGY</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3TUJHF9LW3M8N</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A5BMKZRGHNSRT</th>\n",
       "      <td>354</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABL3H3O3BI8ZD</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFXNF8FWT090W</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANPTDUX6LOGYY</th>\n",
       "      <td>256</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AYW62R027PUT1</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ADD  ADD_NOSWAP\n",
       "workerId                       \n",
       "A11BSFO4LMHPXQ   12          12\n",
       "A126IMAJ4EEE7    26          25\n",
       "A15SUPIZ05ZFCD   41          41\n",
       "A17V85U8PXS4LJ   56          50\n",
       "A196XR61DIW5GU   12          11\n",
       "A19XQH5DG3UO0     3           3\n",
       "A1FLEFIVFT809G   85          80\n",
       "A1HG89IPHXW7LO    4           4\n",
       "A1JGA15NKUP0BB    3           3\n",
       "A1KM8AW99FFRFZ    9           7\n",
       "A1N1EF0MIRSEZZ  294         263\n",
       "A1NBX7UHTU5CKG   48          46\n",
       "A1PF01FF85HUY4   16          16\n",
       "A1PTX4IB9R34LI    3           3\n",
       "A1TARNH07A75CG   22          19\n",
       "A1TYP11M6YZUK8  254         252\n",
       "A1XZ9MUNKFZIJG  132         121\n",
       "A1Z3NTRGIUZ240    4           4\n",
       "A20SL254675EOK   29          27\n",
       "A26U4IKXMXT0ZA   56          54\n",
       "A28T38MOUG43YD   12          12\n",
       "A29V2XPA9H2NAN    7           7\n",
       "A2BADLL5Q78E7D  231         231\n",
       "A2BF3A9KYSEFPO   53          46\n",
       "A2CIFCKECOSW0S  313         274\n",
       "A2HX72NU82J6NZ    9           9\n",
       "A2NGMLBFZ3YQP5   38          37\n",
       "A2OFWFHVQOBY56   10          10\n",
       "A2T5UVJCDX3C5    10           9\n",
       "A2W6XZ8D8VYZCO   33          32\n",
       "A35PLLN5TFI4KW   18          18\n",
       "A3696JXTRKL2FI   12          12\n",
       "A39K5MR4MCSC56  325         291\n",
       "A3DLPY6ABKCXSI   15          14\n",
       "A3J5KTBHZI60H   233         233\n",
       "A3JAOT764X4HYB   14          14\n",
       "A3ROADR7T6811    26          23\n",
       "A3TOHZTNKOTFQL   13          12\n",
       "A3TUCOUVSP9ZGY    6           6\n",
       "A3TUJHF9LW3M8N   12          11\n",
       "A5BMKZRGHNSRT   354         282\n",
       "ABL3H3O3BI8ZD    13          13\n",
       "AFXNF8FWT090W     9           9\n",
       "ANPTDUX6LOGYY   256         244\n",
       "AYW62R027PUT1    17          17"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['ADD'] = adds1['Category']\n",
    "df['ADD_NOSWAP'] = adds['Category']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write adds to file \n",
    "df0=pd.DataFrame()\n",
    "df0['measure'] = adds['List'].values\n",
    "df0['condition'] = 'List'\n",
    "df1=pd.DataFrame()\n",
    "df1['measure'] = adds['Category'].values\n",
    "df1['condition'] = 'Category'\n",
    "df2=pd.DataFrame()\n",
    "df2['measure'] = adds['Pairwise'].values\n",
    "df2['condition'] = 'Pairwise'\n",
    "df = pd.concat([df0,df1,df2])\n",
    "df[['condition','measure']]\n",
    "df.to_csv(\"results/adds_noswap.csv\", index=False)\n",
    "\n",
    "#write removes to file\n",
    "df0=pd.DataFrame()\n",
    "df0['measure'] = removes['List'].values\n",
    "df0['condition'] = 'List'\n",
    "df1=pd.DataFrame()\n",
    "df1['measure'] = removes['Category'].values\n",
    "df1['condition'] = 'Category'\n",
    "df2=pd.DataFrame()\n",
    "df2['measure'] = removes['Pairwise'].values\n",
    "df2['condition'] = 'Pairwise'\n",
    "df = pd.concat([df0,df1,df2])\n",
    "df[['condition','measure']]\n",
    "df.to_csv(\"results/removes_noswap.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
